.\"     Title: hb_report
.\"    Author: [see the "AUTHOR" section]
.\" Generator: DocBook XSL Stylesheets v1.74.0 <http://docbook.sf.net/>
.\"      Date: 09/15/2009
.\"    Manual: Pacemaker documentation
.\"    Source: hb_report 1.2
.\"  Language: English
.\"
.TH "HB_REPORT" "8" "09/15/2009" "hb_report 1\&.2" "Pacemaker documentation"
.\" -----------------------------------------------------------------
.\" * (re)Define some macros
.\" -----------------------------------------------------------------
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" toupper - uppercase a string (locale-aware)
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de toupper
.tr aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ
\\$*
.tr aabbccddeeffgghhiijjkkllmmnnooppqqrrssttuuvvwwxxyyzz
..
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" SH-xref - format a cross-reference to an SH section
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de SH-xref
.ie n \{\
.\}
.toupper \\$*
.el \{\
\\$*
.\}
..
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" SH - level-one heading that works better for non-TTY output
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de1 SH
.\" put an extra blank line of space above the head in non-TTY output
.if t \{\
.sp 1
.\}
.sp \\n[PD]u
.nr an-level 1
.set-an-margin
.nr an-prevailing-indent \\n[IN]
.fi
.in \\n[an-margin]u
.ti 0
.HTML-TAG ".NH \\n[an-level]"
.it 1 an-trap
.nr an-no-space-flag 1
.nr an-break-flag 1
\." make the size of the head bigger
.ps +3
.ft B
.ne (2v + 1u)
.ie n \{\
.\" if n (TTY output), use uppercase
.toupper \\$*
.\}
.el \{\
.nr an-break-flag 0
.\" if not n (not TTY), use normal case (not uppercase)
\\$1
.in \\n[an-margin]u
.ti 0
.\" if not n (not TTY), put a border/line under subheading
.sp -.6
\l'\n(.lu'
.\}
..
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" SS - level-two heading that works better for non-TTY output
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de1 SS
.sp \\n[PD]u
.nr an-level 1
.set-an-margin
.nr an-prevailing-indent \\n[IN]
.fi
.in \\n[IN]u
.ti \\n[SN]u
.it 1 an-trap
.nr an-no-space-flag 1
.nr an-break-flag 1
.ps \\n[PS-SS]u
\." make the size of the head bigger
.ps +2
.ft B
.ne (2v + 1u)
.if \\n[.$] \&\\$*
..
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" BB/BE - put background/screen (filled box) around block of text
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de BB
.if t \{\
.sp -.5
.br
.in +2n
.ll -2n
.gcolor red
.di BX
.\}
..
.de EB
.if t \{\
.if "\\$2"adjust-for-leading-newline" \{\
.sp -1
.\}
.br
.di
.in
.ll
.gcolor
.nr BW \\n(.lu-\\n(.i
.nr BH \\n(dn+.5v
.ne \\n(BHu+.5v
.ie "\\$2"adjust-for-leading-newline" \{\
\M[\\$1]\h'1n'\v'+.5v'\D'P \\n(BWu 0 0 \\n(BHu -\\n(BWu 0 0 -\\n(BHu'\M[]
.\}
.el \{\
\M[\\$1]\h'1n'\v'-.5v'\D'P \\n(BWu 0 0 \\n(BHu -\\n(BWu 0 0 -\\n(BHu'\M[]
.\}
.in 0
.sp -.5v
.nf
.BX
.in
.sp .5v
.fi
.\}
..
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.\" BM/EM - put colored marker in margin next to block of text
.\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.de BM
.if t \{\
.br
.ll -2n
.gcolor red
.di BX
.\}
..
.de EM
.if t \{\
.br
.di
.ll
.gcolor
.nr BH \\n(dn
.ne \\n(BHu
\M[\\$1]\D'P -.75n 0 0 \\n(BHu -(\\n[.i]u - \\n(INu - .75n) 0 0 -\\n(BHu'\M[]
.in 0
.nf
.BX
.in
.fi
.\}
..
.\" -----------------------------------------------------------------
.\" * set default formatting
.\" -----------------------------------------------------------------
.\" disable hyphenation
.nh
.\" disable justification (adjust text to left margin only)
.ad l
.\" -----------------------------------------------------------------
.\" * MAIN CONTENT STARTS HERE *
.\" -----------------------------------------------------------------
.SH "Name"
hb_report \- create report for CRM based clusters (Pacemaker)
.SH "Synopsis"
.sp
\fBhb_report\fR \-f {time|"cts:"testnum} [\-t time] [\-u user] [\-l file] [\-n nodes] [\-E files] [\-p patt] [\-L patt] [\-e prog] [\-MSDCA] dest
.SH "DESCRIPTION"
.sp
The hb_report(1) is a utility to collect all information (logs, configuration files, system information, etc) relevant to Pacemaker (CRM) over the given period of time\&.
.SH "OPTIONS"
.PP
dest
.RS 4
The destination directory\&. Must be an absolute path\&. The resulting tarball is placed in the parent directory and contains the last directory element of this path\&. Typically something like /tmp/standby\-failed\&.
.RE
.PP
\fB\-f\fR { time | "cts:"testnum }
.RS 4
The start time from which to collect logs\&. The time is in the format as used by the Date::Parse perl module\&. For cts tests, specify the "cts:" string followed by the test number\&. This option is required\&.
.RE
.PP
\fB\-t\fR time
.RS 4
The end time to which to collect logs\&. Defaults to now\&.
.RE
.PP
\fB\-n\fR nodes
.RS 4
A list of space separated hostnames (cluster members)\&. hb_report may try to find out the set of nodes by itself, but if it runs on the loghost which, as it is usually the case, does not belong to the cluster, that may be difficult\&. Also, OpenAIS doesn\(cqt contain a list of nodes and if Pacemaker is not running, there is no way to find it out automatically\&. This option is cummulative (i\&.e\&. use \-n "a b" or \-n a \-n b)\&.
.RE
.PP
\fB\-l\fR file
.RS 4
Log file location\&. If, for whatever reason, hb_report cannot find the log files, you can specify its absolute path\&.
.RE
.PP
\fB\-E\fR files
.RS 4
Extra log files to collect\&. This option is cummulative\&. By default, /var/log/messages are collected along with the cluster logs\&.
.RE
.PP
\fB\-M\fR
.RS 4
Don\(cqt collect extra log files, but only the file containing messages from the cluster subsystems\&.
.RE
.PP
\fB\-L\fR patt
.RS 4
A list of regular expressions to match in log files for analysis\&. This option is additive (default: "CRIT: ERROR:")\&.
.RE
.PP
\fB\-p\fR patt
.RS 4
Regular expression to match variables to be sanitized (replaced by a string of asterisks)\&. If you don\(cqt want information to be exposed in your report, you can specify here a set of patterns to match variables in the CIB and pengine files\&. stonith_host directives in ha\&.cf are also sanitized\&. Logs are not sanitized\&. This option is cummulative (default: "passw\&.*")\&.
.RE
.PP
\fB\-A\fR
.RS 4
This is an OpenAIS cluster\&. hb_report has some heuristics to find the cluster stack, but that is not always reliable\&. By default, hb_report assumes that it is run on a Heartbeat cluster\&.
.RE
.PP
\fB\-u\fR user
.RS 4
The ssh user\&. hb_report will try to login to other nodes without specifying a user, then as "root", and finally as "hacluster"\&. If you have another user for administration over ssh, please use this option\&.
.RE
.PP
\fB\-S\fR
.RS 4
Single node operation\&. Run hb_report only on this node and don\(cqt try to start slave collectors on other members of the cluster\&. Under normal circumstances this option is not needed\&. Use if ssh(1) does not work to other nodes\&.
.RE
.PP
\fB\-h\fR
.RS 4
Show usage and some examples\&.
.RE
.PP
\fB\-D\fR (obsolete)
.RS 4
Don\(cqt invoke editor to fill the description text file\&.
.RE
.PP
\fB\-e\fR prog (obsolete)
.RS 4
Your favourite text editor\&. Defaults to $EDITOR, vim, vi, emacs, or nano, whichever is found first\&.
.RE
.PP
\fB\-C\fR (obsolete)
.RS 4
Remove the destination directory once the report has been put in a tarball\&.
.RE
.SH "EXAMPLES"
.sp
Last night during the backup there were several warnings encountered (logserver is the log host):
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
logserver# hb_report \-f 3:00 \-t 4:00 \-n "node1 node2" /tmp/report
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
collects everything from all nodes from 3am to 4am last night\&. The files are compressed to a tarball /tmp/report\&.tar\&.bz2\&.
.sp
Just found a problem during testing:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# note the current time
node1# date
Fri Sep 11 18:51:40 CEST 2009
node1# /etc/init\&.d/heartbeat start
node1# nasty\-command\-that\-breaks\-things
node1# sleep 120 #wait for the cluster to settle
node1# hb_report \-f 18:51 /tmp/hb1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# if hb_report can\'t figure out the stack
node1# hb_report \-f 18:51 \-A /tmp/hb1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# if hb_report can\'t figure out the cluster members
node1# hb_report \-f 18:51 \-n "node1 node2" /tmp/hb1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
The files are compressed to a tarball /tmp/hb1\&.tar\&.bz2\&.
.SH "INTERPRETING RESULTS"
.sp
The compressed tar archive is the final product of hb_report\&. This is one example of its content, for a CTS test case on a three node OpenAIS cluster:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
$ ls \-RF 001\-Restart
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
001\-Restart:
analysis\&.txt     events\&.txt  logd\&.cf       s390vm13/  s390vm16/
description\&.txt  ha\-log\&.txt  openais\&.conf  s390vm14/
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
001\-Restart/s390vm13:
STOPPED  crm_verify\&.txt  hb_uuid\&.txt  openais\&.conf@   sysinfo\&.txt
cib\&.txt  dlm_dump\&.txt    logd\&.cf@     pengine/        sysstats\&.txt
cib\&.xml  events\&.txt      messages     permissions\&.txt
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
001\-Restart/s390vm13/pengine:
pe\-input\-738\&.bz2  pe\-input\-740\&.bz2  pe\-warn\-450\&.bz2
pe\-input\-739\&.bz2  pe\-warn\-449\&.bz2   pe\-warn\-451\&.bz2
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
001\-Restart/s390vm14:
STOPPED  crm_verify\&.txt  hb_uuid\&.txt  openais\&.conf@   sysstats\&.txt
cib\&.txt  dlm_dump\&.txt    logd\&.cf@     permissions\&.txt
cib\&.xml  events\&.txt      messages     sysinfo\&.txt
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
001\-Restart/s390vm16:
STOPPED  crm_verify\&.txt  hb_uuid\&.txt  messages        sysinfo\&.txt
cib\&.txt  dlm_dump\&.txt    hostcache    openais\&.conf@   sysstats\&.txt
cib\&.xml  events\&.txt      logd\&.cf@     permissions\&.txt
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
The top directory contains information which pertains to the cluster or event as a whole\&. Files with exactly the same content on all nodes will also be at the top, with per\-node links created (as it is in this example the case with openais\&.conf and logd\&.cf)\&.
.sp
The cluster log files are named ha\-log\&.txt regardless of the actual log file name on the system\&. If it is found on the loghost, then it is placed in the top directory\&. Files named messages are excerpts of /var/log/messages from nodes\&.
.sp
Most files are copied verbatim or they contain output of a command\&. For instance, cib\&.xml is a copy of the CIB found in /var/lib/heartbeat/crm/cib\&.xml\&. crm_verify\&.txt is output of the crm_verify(8) program\&.
.sp
Some files are result of a more involved processing:
.PP
\fBanalysis\&.txt\fR
.RS 4
A set of log messages matching user defined patterns (may be provided with the \-L option)\&.
.RE
.PP
\fBevents\&.txt\fR
.RS 4
A set of log messages matching event patterns\&. It should provide information about major cluster motions without unnecessary details\&. These patterns are devised by the cluster experts\&. Currently, the patterns cover membership and quorum changes, resource starts and stops, fencing (stonith) actions, and cluster starts and stops\&. events\&.txt is always generated for each node\&. In case the central cluster log was found, also combined for all nodes\&.
.RE
.PP
\fBpermissions\&.txt\fR
.RS 4
One of the more common problem causes are file and directory permissions\&. hb_report looks for a set of predefined directories and checks their permissions\&. Any issues are reported here\&.
.RE
.PP
\fBbacktraces\&.txt\fR
.RS 4
gdb generated backtrace information for cores dumped within the specified period\&.
.RE
.PP
\fBsysinfo\&.txt\fR
.RS 4
Various release information about the platform, kernel, operating system, packages, and anything else deemed to be relevant\&. The static part of the system\&.
.RE
.PP
\fBsysstats\&.txt\fR
.RS 4
Output of various system commands such as ps(1), uptime(1), netstat(8), and ifconfig(8)\&. The dynamic part of the system\&.
.RE
.sp
description\&.txt should contain a user supplied description of the problem, but since it is very seldom used, it will be dropped from the future releases\&.
.SH "PREREQUISITES"
.PP
ssh
.RS 4
It is not strictly required, but you won\(cqt regret having a password\-less ssh\&. It is not too difficult to setup and will save you a lot of time\&. If you can\(cqt have it, for example because your security policy does not allow such a thing, or you just prefer menial work, then you will have to resort to the semi\-manual semi\-automated report generation\&. See below for instructions\&.

If you need to supply a password for your passphrase/login, then please use the
\FC\-u\F[]
option\&.
.RE
.PP
Times
.RS 4
In order to find files and messages in the given period and to parse the
\FC\-f\F[]
and
\FC\-t\F[]
options,
\FChb_report\F[]
uses perl and one of the
\FCDate::Parse\F[]
or
\FCDate::Manip\F[]
perl modules\&. Note that you need only one of these\&. Furthermore, on nodes which have no logs and where you don\(cqt run
\FChb_report\F[]
directly, no date parsing is necessary\&. In other words, if you run this on a loghost then you don\(cqt need these perl modules on the cluster nodes\&.

On rpm based distributions, you can find
\FCDate::Parse\F[]
in
\FCperl\-TimeDate\F[]
and on Debian and its derivatives in
\FClibtimedate\-perl\F[]\&.
.RE
.PP
Core dumps
.RS 4
To backtrace core dumps gdb is needed and the packages with the debugging info\&. The debug info packages may be installed at the time the report is created\&. Let\(cqs hope that you will need this really seldom\&.
.RE
.SH "TIMES"
.sp
Specifying times can at times be a nuisance\&. That is why we have chosen to use one of the perl modules\(emthey do allow certain freedom when talking dates\&. You can either read the instructions at the Date::Parse examples page\&. or just rely on common sense and try stuff like:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
3:00          (today at 3am)
15:00         (today at 3pm)
2007/9/1 2pm  (September 1st at 2pm)
Tue Sep 15 20:46:27 CEST 2009 (September 15th etc)
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
\FChb_report\F[] will (probably) complain if it can\(cqt figure out what do you mean\&.
.sp
Try to delimit the event as close as possible in order to reduce the size of the report, but still leaving a minute or two around for good measure\&.
.sp
\FC\-f\F[] is not optional\&. And don\(cqt forget to quote dates when they contain spaces\&.
.SH "Should I send all this to the rest of Internet?"
.sp
We make an effort to remove sensitive data from the configuration (CIB, ha\&.cf, and transition graphs)\&. By default, parameters starting matching \fIpassw\&.\fR\fI\fR\fI are replaced by a string of \fR\fI\fR\&. Use the \FC\-p\F[] option to specify additional regular expressions to match variable names which may contain information you don\(cqt want to leak\&. For example:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# hb_report \-f 18:00 \-p "user\&.*" \-p "secret\&.*" /var/tmp/report
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
Logs and other files are not filtered\&.
.SH "LOGS"
.sp
It may be tricky to find syslog logs\&. The scheme used is to log a unique message on all nodes and then look it up in the usual syslog locations\&. This procedure is not foolproof, in particular if the syslog files are in a non\-standard directory\&. We look in /var/log /var/logs /var/syslog /var/adm /var/log/ha /var/log/cluster\&. In case we can\(cqt find the logs, please supply their location:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# hb_report \-f 5pm \-l /var/log/cluster1/ha\-log \-S /tmp/report_node1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
If you have different log locations on different nodes, well, perhaps you\(cqd like to make them the same and make life easier for everybody\&.
.sp
Files starting with "ha\-" are preferred\&. In case syslog sends messages to more than one file, if one of them is named ha\-log or ha\-debug those will be favoured to syslog or messages\&.
.sp
hb_report supports also archived logs in case the period specified extends that far in the past\&. The archives must reside in the same directory as the current log and their names must be prefixed with the name of the current log (syslog\-1\&.gz or messages\-20090105\&.bz2)\&.
.sp
If there is no separate log for the cluster, possibly unrelated messages from other programs are included\&. We don\(cqt filter logs, just pick a segment for the period you specified\&.
.SH "MANUAL REPORT COLLECTION"
.sp
So, your ssh doesn\(cqt work\&. In that case, you will have to run this procedure on all nodes\&. Use \FC\-S\F[] so that we don\(cqt bother with ssh:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# hb_report \-f 5:20pm \-t 5:30pm \-S /tmp/report_node1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
If you also have a log host which is not in the cluster, then you\(cqll have to copy the log to one of the nodes and tell us where it is:
.sp
.if n \{\
.RS 4
.\}
.fam C
.ps -1
.nf
.BB lightgray
# hb_report \-f 5:20pm \-t 5:30pm \-l /var/tmp/ha\-log \-S /tmp/report_node1
.EB lightgray
.fi
.fam
.ps +1
.if n \{\
.RE
.\}
.sp
If you reconsider and want the ssh setup, take a look at the CTS README file for instructions\&.
.SH "OPERATION"
.sp
hb_report collects files and other information in a fairly straightforward way\&. The most complex tasks are discovering the log file locations (if syslog is used which is the most common case) and coordinating the operation on multiple nodes\&.
.sp
The instance of hb_report running on the host where it was invoked is the master instance\&. Instances running on other nodes are slave instances\&. The master instance communicates with slave instances by ssh\&. There are multiple ssh invocations per run, so it is essential that the ssh works without password, i\&.e\&. with the public key authentication and authorized_keys\&.
.sp
The operation consists of three phases\&. Each phase must finish on all nodes before the next one can commence\&. The first phase consists of logging unique messages through syslog on all nodes\&. This is the shortest of all phases\&.
.sp
The second phase is the most involved\&. During this phase all local information is collected, which includes:
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
logs (both current and archived if the start time is far in the past)
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
various configuration files (openais, heartbeat, logd)
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
the CIB (both as xml and as represented by the crm shell)
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
pengine inputs (if this node was the DC at any point in time over the given period)
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
system information and status
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
package information and status
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
dlm lock information
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
backtraces (if there were core dumps)
.RE
.sp
The third phase is collecting information from all nodes and analyzing it\&. The analyzis consists of the following tasks:
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
identify files equal on all nodes which may then be moved to the top directory
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
save log messages matching user defined patterns (defaults to ERRORs and CRITical conditions)
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
report if there were coredumps and by whom
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
report crm_verify(8) results
.RE
.sp
.RS 4
.ie n \{\
\h'-04'\(bu\h'+03'\c
.\}
.el \{\
.sp -1
.IP \(bu 2.3
.\}
save log messages matching major events to events\&.txt
.RE
.SH "BUGS"
.sp
Finding logs may at times be extremely difficult, depending on how weird the syslog configuration\&. It would be nice to ask syslog\-ng developers to provide a way to find out the log destination based on facility and priority\&.
.sp
hb_report can function in a satisfactory way only if ssh works to all nodes using authorized_keys (without password)\&.
.sp
In case there is no central log host, events and other log information do not provide a single cluster view\&. Since it seems to be that most users do not have loghost deployed, it may be beneficial to implement a log combine utility which would sort logs based on timestamps (for ha\-log\&.txt and events\&.txt)\&.
.sp
There are way too many options\&.
.SH "AUTHOR"
.sp
Written by Dejan Muhamedagic, <dejan@suse\&.de>
.SH "RESOURCES"
.sp
Pacemaker: http://clusterlabs\&.org/
.sp
Heartbeat and other Linux HA resources: http://linux\-ha\&.org/
.sp
OpenAIS: http://www\&.openais\&.org/
.SH "SEE ALSO"
.sp
Date::Parse(3)
.SH "COPYING"
.sp
Copyright (C) 2007\-2009 Dejan Muhamedagic\&. Free use of this software is granted under the terms of the GNU General Public License (GPL)\&.
